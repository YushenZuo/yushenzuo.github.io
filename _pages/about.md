---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

I am Yushen Zuo, currently a research assistant at <a href='https://www.polyu.edu.hk/'>The Hong Kong Polytechnic University (PolyU)</a>, working under the guidance of <a href='https://www.eie.polyu.edu.hk/~enkmlam/'>Prof. Kenneth K. M. Lam</a> and in close collaboration with <a href='https://junxiao01.github.io/'>Jun Xiao</a>.

Prior to this, I was an Applied Scientist at <a href='https://www.microsoft.com/en-us'>Microsoft</a>. Before that, I was interned at <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/'>Microsoft Research Asia</a> and <a href='https://github.com/TencentYoutuResearch'>Tencent Youtu Lab</a>. I hold a master's degree from <a href='https://www.tsinghua.edu.cn/en/'>Tsinghua University</a> and a bachelor's degree from <a href='https://en.xidian.edu.cn/'>Xidian University</a>. 

I am actively seeking PhD opportunities worldwide. My research areas include low-level vision; image translation and generation; object detection and segmentation; vision-language model safety. 

Here is my <a href="cv/Yushen_CV_Oct2024.pdf">**CV**</a>.

Google citation: <a href='https://scholar.google.com/citations?user=C2CDJOoAAAAJ'><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2FYushenZuo%2Fyushenzuo.github.io@google-scholar-stats%2Fgs_data_shieldsio.json&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>

<!-- My research interest includes machine learning and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=C2CDJOoAAAAJ'>google scholar citations <strong><span id='total_cit'>100+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=C2CDJOoAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# ğŸ”¥ News
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ A paper is submitted to ICASSP 2025. 
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ 2nd place in <a herf='https://codalab.lisn.upsaclay.fr/competitions/17705'>AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content</a> (ECCV 2024 Workshop) our method 'Fast Sequential Motion Diffusion (FSMD)' is selected to present in the summary paper.
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ 'Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning' is accpeted by AI4VA workshop in ECCV 2024. 
- *2024.04*: &nbsp;ğŸ‰ğŸ‰ Start my research assistant life at The Hong Kong Polytechnic University (PolyU). 
- *2021.03*: &nbsp;ğŸ‰ğŸ‰ Rank 10/60 in NTIRE 2021 Challenge on Image Deblurring and our method 'Visual Token Transformer for Image Restoration' is selected to present in the summary paper.
- *2019.07*: &nbsp;ğŸ‰ğŸ‰ 'Low-resolution palmprint image denoising by generative adversarial networks' is accepted by Neurocomputing 2019. 

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AI4VA@ECCV 2024</div><img src='images/MuvieCastONeSDiff_pipe.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

<!-- [Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->
Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning

**Yushen Zuo**, Jun Xiao, Kin-Chung Chan, Rongkang Dong, Cuixin Yang, Zongqi HE, Hao Xie, Kin-Man Lam

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AIM@ECCV 2024</div><img src='images/AIM2024.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

<!-- [Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->
[AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content](https://arxiv.org/pdf/2409.17256)

Marcos V. Conde, Zhijun Lei, Wen Li, Christos Bampis, Ioannis Katsavounidis, Radu Timofte, **Yushen Zuo** et al.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPRW 2021</div><img src='images/W21.jpg' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[NTIRE 2021 Challenge on Image Deblurring](https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Nah_NTIRE_2021_Challenge_on_Image_Deblurring_CVPRW_2021_paper.pdf)

Seungjun Nah, Sanghyun Son, Suyoung Lee, Radu Timofte, Kyoung Mu Lee, **Yushen Zuo** et al.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neurocomputing 2019</div><img src='images/N19.jpg' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[Low-resolution palmprint image denoising by generative adversarial networks](https://www.sciencedirect.com/science/article/pii/S0925231219307313)

Shengjie Chen, Shuo Chen, Zhenhua Guo, **Yushen Zuo**

</div>
</div>

# ğŸ’» Work Experience
- *2024.04 - Now*, Research Assistant, <a href='https://www.polyu.edu.hk/en/'>The Hong Kong Polytechnic University (PolyU)</a>
  - Artificial Intelligence and Signal Processing Laboratory
    - Accelerated Diffusion in Image Processing Task (e.g., Style Transfer, Image Translation)
    - Efficient Video Super-Resolution
    - Old movie restoration and enhancement
    - Novel-view synthesis with 3D Gaussian Splatting
    - Image Processing and Diffusion in vision-language model safety and defense
- *2022.08 - 2024.03*, Applied Scientist, <a href='https://www.microsoft.com/en-us'>Microsoft</a>
  - Bing News - Recommendation system
    - Explainable AI
      - Use SHAP to calculate feature contribution to ranking score for a better explanation of model's output.
      - Show users why he/she sees this recommended content based on the recall path with a mapping method.
      - Currently applied to all Bing News channels (e.g. Edge homepage), while collecting user's feedback to modify the mapping method.-
    - Dynamic quota allocation
      - Train a classification model to determine whether a news recommendation request is triggered by user or by prerender/other backend tasks based on request's features and the corresponding user's engagement features. (Result: AUC > 0.8 in test dataset built on Bing News Recommendation database)
      - Based on the result of classification model, reduce the quota of each recall path in Ranker for requests predicted to be `Not User-trigger' to reduce computational cost.
      - Product performance: Reduce 20% computing resources usage without losing performance.
  - Bing Whole Page - Large Language Model Application
    - Answer triggering in Bing Search - Real Estate Related
      - Use LLM (GPT-3.5) to label challenging samples from web result and get 1.3M new training samples.
      - Recall in test dateset improved from 0.54 to 0.73 after training with new training set with LLM labeling.
      - Product performance: 3\% increase in answer trigger rate (answer triggers Bing real estate application) in Bing search, and 4.1K gain in DAU (Daily Active Users) of Bing real estate application.
- *2021.07 - 2022.07*, Research Intern, <a href='https://www.microsoft.com/en-us/research/group/speech/'>Multi-Modal Interaction (MMI) Group</a>, <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/'>Microsoft Research Asia</a>
  - Rotated object detection (multi-directional table detection)
    - Design an anchor-free two-stage detector for rotated object detection.
    - Achieve state-of-the-art performance in production dataset and contribute to Azure OCR API (3B monthly activate user).
    - 'Stars-of-tomorrow' award of MSRA Intern Program.
- *2020.10 - 2021.05*, Research Intern, <a href='https://github.com/TencentYoutuResearch'>Tencent Youtu Lab</a>
  - UniInst: Detection free and NMS free instance segmentation
    - Instance-aware One-to-one Assignment and MaskIOU Branch.
    - SOTA mask AP on COCO test-dev 2017 dataset and OCHuman dataset.
    - Patent: CN114332457A[P]

# ğŸ– Honors and Awards
- *2024.08*  AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content - 2nd place.
- *2022.06*  'Stars-of-tomorrow' award of Microsoft Research Asia Intern Program.
- *2021.03*  CVPR 2021 NTIRE Image Deblurring Challenge - Track1. Low Resolution (10 / 60)
- *2021.01*  Kaggle NFL 1st and Future - Impact Detection, Silver medal (23 / 459)
- *2020.12*  Champion of the 1st Ocean Target Detection International Challenge (1 / 151)
- *2018.05*  Meritorious winner in Interdisciplinary Contest in Modeling (ICM)

# ğŸ“– Educations
- *2019.06 - 2022.06*, Tsinghua University.
- *2015.09 - 2019.06*, Xidian University.

