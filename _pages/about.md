---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

Hello, I am Yushen Zuo, currently a research assistant at <a href='https://www.polyu.edu.hk/'>The Hong Kong Polytechnic University (PolyU)</a>, working under the guidance of <a href='https://www.eie.polyu.edu.hk/~enkmlam/'>Prof. Kenneth K. M. Lam</a> and in close collaboration with <a href='https://junxiao01.github.io/'>Jun Xiao</a>.

Prior to this, I was an Applied Scientist at <a href='https://www.microsoft.com/en-us'>Microsoft</a>. Before that, I was interned at <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/'>Microsoft Research Asia</a> and <a href='https://github.com/TencentYoutuResearch'>Tencent Youtu Lab</a>. I hold a master's degree from <a href='https://www.tsinghua.edu.cn/en/'>Tsinghua University</a> and a bachelor's degree from <a href='https://en.xidian.edu.cn/'>Xidian University</a>. 

I am actively seeking PhD opportunities worldwide. My research areas include low-level vision; image translation and generation; object detection and segmentation; 3D vision; vision-language model safety. 

Here is my <a href="cv/CV_YushenZuo_Dec2024.pdf">**CV**</a>.

Google citation: <a href='https://scholar.google.com/citations?user=C2CDJOoAAAAJ'><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2FYushenZuo%2Fyushenzuo.github.io@google-scholar-stats%2Fgs_data_shieldsio.json&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>

<!-- My research interest includes machine learning and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=C2CDJOoAAAAJ'>google scholar citations <strong><span id='total_cit'>100+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=C2CDJOoAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# üî• News
- *2025.01*: &nbsp;üéâüéâ Our paper <a href='https://arxiv.org/pdf/2501.11508'> See In Detail: Enhancing Sparse-view 3D Gaussian Splatting with Local Depth and Semantic Regularization</a> is accpeted by **ICASSP 2025**.
- *2024.11*: &nbsp;üéâüéâ Our paper for Vision-Language Model (VLM) safety is submitted to **CVPR 2025**.  
- *2024.08*: &nbsp;üéâüéâ 2nd place in <a href='https://codalab.lisn.upsaclay.fr/competitions/17705'>AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content</a> **in ECCV 2024** and our method **Fast Sequential Motion Diffusion (FSMD)** is selected to present in the summary <a href='https://arxiv.org/pdf/2409.17256'>paper</a>.
- *2024.08*: &nbsp;üéâüéâ Our paper **Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning** is accpeted by <a href='https://sites.google.com/view/ai4vaeccv2024'>AI for Visual Arts Workshop and Challenges (AI4VA)</a> in **ECCV 2024**. 
- *2024.04*: &nbsp;üéâüéâ Join <a href='https://www.polyu.edu.hk/'>The Hong Kong Polytechnic University (PolyU)</a> as a research assistant.
- *2022.07*: &nbsp;üéâüéâ Join <a href='https://www.microsoft.com/en-us'>Microsoft</a> as an applied scientist and focus on recommendation system and large language model application in Bing.
- *2022.06*: &nbsp;üéâüéâ 'Stars-of-tomorrow' award of MSRA Internship Program.
- *2021.07*: &nbsp;üéâüéâ Join <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/'>Microsoft Research Asia (MSRA)</a> as a research intern in <a href='https://www.microsoft.com/en-us/research/group/speech/'>Multi-Modal Interaction (MMI) Group</a> (directed by <a href='https://www.microsoft.com/en-us/research/people/qianghuo/'>Dr. Qiang Huo</a>) and cooperate with Azure OCR team for multi-directional table detection in PDF image.
- *2021.03*: &nbsp;üéâüéâ Rank 10 / 60 in <a href='https://competitions.codalab.org/competitions/28073'>NTIRE 2021 Challenge on Image Deblurring</a> in **CVPR 2021** and our method **Visual Token Transformer for Image Restoration** is selected to present in the summary <a href='https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Nah_NTIRE_2021_Challenge_on_Image_Deblurring_CVPRW_2021_paper.pdf'>paper</a>.
- *2019.07*: &nbsp;üéâüéâ Our paper <a href='https://www.sciencedirect.com/science/article/pii/S0925231219307313'>Low-resolution palmprint image denoising by generative adversarial networks</a> is accepted by **Neurocomputing 2019**. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AI4VA@ECCV 2024</div><img src='images/MuvieCastONeSDiff_pipe.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning](https://arxiv.org/pdf/2411.10130)
<!-- Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning -->

**Yushen Zuo**, Jun Xiao, Kin-Chung Chan, Rongkang Dong, Cuixin Yang, Zongqi HE, Hao Xie, Kin-Man Lam

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AIM@ECCV 2024</div><img src='images/AIM2024.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

<!-- [Towards Multi-View Consistent Style Transfer with One-Step Diffusion via Vision Conditioning](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->
[AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content](https://arxiv.org/pdf/2409.17256)

Marcos V. Conde, Zhijun Lei, Wen Li, Christos Bampis, Ioannis Katsavounidis, Radu Timofte, **Yushen Zuo** et al.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPRW 2021</div><img src='images/W21.jpg' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[NTIRE 2021 Challenge on Image Deblurring](https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Nah_NTIRE_2021_Challenge_on_Image_Deblurring_CVPRW_2021_paper.pdf)

Seungjun Nah, Sanghyun Son, Suyoung Lee, Radu Timofte, Kyoung Mu Lee, **Yushen Zuo** et al.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neurocomputing 2019</div><img src='images/N19.jpg' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[Low-resolution palmprint image denoising by generative adversarial networks](https://www.sciencedirect.com/science/article/pii/S0925231219307313)

Shengjie Chen, Shuo Chen, Zhenhua Guo, **Yushen Zuo**

</div>
</div>

# üíª Work and Research Experience
- **2024.04 - Now**, Research Assistant, <a href='https://www.polyu.edu.hk/en/'>The Hong Kong Polytechnic University (PolyU)</a>
  - Artificial Intelligence and Signal Processing Laboratory
    - Accelerated Diffusion for Image Processing (e.g., Style Transfer, Image Translation)
      - Focus on the stylization of multi-view images in 3D scenes and proposed OSDiffST, a novel style transfer method based on a one-step diffusion model.
      - Incorporate LoRA adapters to rapidly adapt the pre-trained diffusion model for style transfer. Propose a vision condition module for efficient style information extraction and injection.
      - Use two additional loss functions to align color distribution and improve structural similarity for enhancing visual quality and maintaining multi-view consistency across images from different viewpoints after stylization.
      - Research paper is accepted by the <a href='https://sites.google.com/view/ai4vaeccv2024'>AI for Visual Arts Workshop and Challenges (AI4VA)</a> in **ECCV 2024**.
      - We are now expanding our approach by designing new adapter and applying our framework to more image processing task (e.g., image translation).
    - Efficient Video Super-Resolution
      - Focus on real-time video super resolution.
      - Proposed Fast Sequential Motion Diffusion (FSMD) to achieve real time video super resolution.
      - 2nd place in <a href='https://codalab.lisn.upsaclay.fr/competitions/17705'>AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content</a> in **ECCV 2024**.
    <!-- - Old movie restoration and enhancement -->
    - Novel view synthesis under sparse view with 3D Gaussian Splatting
      - Focus on enhancing 3D Gaussian Splatting for novel view synthesis under sparse view based on local depth and semantic regularization.
      - Our research paper is accepted by **ICASSP 2025**.
    - Image Processing and Diffusion in vision-language model safety and defense
      - Explores VLM safety and the effectiveness of diffusion in defense.
      - Research paper is planned to submit to **CVPR 2025**.
- **2022.08 - 2024.03**, Applied Scientist, <a href='https://www.microsoft.com/en-us'>Microsoft</a>
  - Bing News - Recommendation system
    - Explainable AI
      - Use SHAP to calculate feature contribution to ranking score for a better explanation of model's output.
      - Show users why he/she sees this recommended content based on the recall path with a mapping method.
      - Applied to all Bing News channels (e.g. Edge homepage), while collecting user's feedback to modify the mapping method.
    - Dynamic quota allocation
      - Train a classification model to determine whether a news recommendation request is triggered by user or by prerender/other backend tasks based on request's features and the corresponding user's engagement features. (Result: AUC > 0.8 in test dataset built on Bing News Recommendation database)
      - Based on the result of classification model, reduce the quota of each recall path in Ranker for requests predicted to be `Not User-trigger' to reduce computational cost.
      - Product performance: Reduce 20% computing resources usage without losing performance.
  - Bing Whole Page - Large Language Model Application
    - Answer triggering in Bing Search - Real Estate Related
      - Use LLM (GPT-3.5) to label challenging samples from web result and get 1.3M new training samples.
      - Train answer triggering model based on new training set augmented with samples by LLM labeling.
      - Recall in test dateset improved from 0.54 to 0.73.
      - Product performance: 3% increase in answer trigger rate (answer triggers Bing real estate application) in Bing search, and 4.1K gain in DAU (Daily Active Users) of Bing real estate application.
- **2021.07 - 2022.07**, Research Intern, <a href='https://www.microsoft.com/en-us/research/group/speech/'>Multi-Modal Interaction (MMI) Group</a>, <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/'>Microsoft Research Asia</a>
  - Rotated object detection (multi-directional table detection in PDF image)
    - Design an anchor-free two-stage detector for rotated object detection.
    - Design sequence-invariant loss and relative-offset for rotated object detector training.
    - Stable performance under different image rotation angles in production dataset (F-score fluctuation < 0.02).
    - Achieve state-of-the-art performance in production dataset and contribute to Azure OCR API (3B monthly activate user).
    - 'Stars-of-tomorrow' award of MSRA Internship Program.
- **2020.10 - 2021.05**, Research Intern, <a href='https://github.com/TencentYoutuResearch'>Tencent Youtu Lab</a>
  - UniInst: Detection free and NMS free instance segmentation
    - Instance-aware One-to-one Assignment: Use Hungarian matching to assign the best matching feature point to the target as positive point according to the classification score and segmentation mask accuracy.
    - MaskIOU Branch: During training, learn to predict the IOU of the generated Mask. During inference, multiply it's IOU prediction for generated masks with the classification score as the final confidence.
    - SOTA mask AP on COCO test-dev 2017 dataset and OCHuman dataset.
    - Patent: CN114332457A[P]
- **2020.05 - 2021.06**, Postgraduate, <a href='https://www.tsinghua.edu.cn/en/'>Tsinghua University</a>
  - Visual Token Transformer for Image Restoration
    - First attempt to use visual token-based transformer in image restoration.
    - Neural network learn to divide images into different groups and map them to visual tokens without manual rules.
    - Design transformer block based on visual token to extract the non-local/multi-scale self-similarity of image.
    - Token-based transformer reduces computation cost from $O(n^{2})$ to $O(n)$ compared to vanilla transformer with comparable image restoration performance.
    - Included in <a href='https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Nah_NTIRE_2021_Challenge_on_Image_Deblurring_CVPRW_2021_paper.pdf'>NTIRE 2021 Challenge on Image Deblurring</a> in **CVPR 2021**. (10 / 60)
    - Project report (Applied in various low-level vision tasks): <a href='https://drive.google.com/file/d/1g4MtypKjdK4lX4i9TGwItAlo5FGFw-00/view?usp=sharing'>Visual Token Transformer for Image Restoration.pdf</a>.
- **2019.01 - 2019.06**, Postgraduate, <a href='https://www.tsinghua.edu.cn/en/'>Tsinghua University</a>
  - Low Resolution Palmprint Image Denoising
    - Palmprint recognition methods are sensitive to image noise and need an effective denoising algorithm.
    - First attempt at end-to-end denoising of low-resolution palmprint images by neural networks.
    - Design a generative adversarial network (GAN)-based model to address multiple types of noise in palmprint image and reserve more orientation information with Gabor loss in training.
    - Collect Data from PolyU palmprint database and IITD database to build train/test dataset and generate noisy image by adding different types of noise.
    - Outperforms existing state-of-the-art methods in both image denoising quality and palmprint recognition accuracy in test dataset with different types of noise. Average EER (equal error rate) of palmprint recognition decreased from 10.841% to 1.532% after denoising.


# üéñ Honors and Awards
- *2024.08*  AIM 2024 Challenge on Efficient Video Super-Resolution for AV1 Compressed Content - 2nd place.
- *2022.06*  'Stars-of-tomorrow' award of Microsoft Research Asia Intern Program.
- *2021.03*  CVPR 2021 NTIRE Image Deblurring Challenge - Track1. Low Resolution (10 / 60)
- *2021.01*  Kaggle NFL 1st and Future - Impact Detection, Silver medal (23 / 459)
- *2020.12*  Champion of the 1st Ocean Target Detection International Challenge (1 / 151)
- *2018.05*  Meritorious winner in Interdisciplinary Contest in Modeling (ICM)

# üìñ Educations
- *2019.06 - 2022.06*, Tsinghua University.
- *2015.09 - 2019.06*, Xidian University.


<!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=IsWL1bUO4XiHmP_fOnirWaUkR5c2kK5AlF1WA8PRDDo&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script> -->
